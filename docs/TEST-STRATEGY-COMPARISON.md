# Test Strategy Comparison: Manual vs Autogenerated

## Overview

For Phase 4 of the universal-command migration, we created manual tests for framework validation. The system also supports autogenerated test stubs via `sc requirement generate-tests`. This document compares both approaches.

## Manual Tests (Created for Framework Validation)

### Purpose

Validate that LazyUniversalCommand framework features work correctly (P0-1 through P0-4).

### Location

- `packages/universal-command/src/commands/{category}/__tests__/{category}-commands.test.ts`

### Examples

**Agent Commands** (`src/commands/agent/__tests__/agent-commands.test.ts`)

- 19 tests total
- Tests: metadata validation, parameter validation, P0-2 positional args, P0-3 lazy loading, MCP interface, CLI generation, tree integration

**WIP Commands** (`src/commands/workflow/__tests__/wip-commands.test.ts`)

- 30 tests total (6 tests × 5 commands)
- Same pattern as agent commands

### Test Structure

```typescript
describe('Agent Status Command (Universal Command)', () => {
  it('should have correct metadata', () => {
    expect(agentStatusCommand.name).toBe('agent status');
    expect(agentStatusCommand.category).toBe('agent');
  });

  it('should validate no parameters', () => {
    const result = agentStatusCommand.validateArgs({});
    expect(result.valid).toBe(true);
  });

  it('should pass P0-3: Lazy Loading', async () => {
    const cmd = agentStatusCommand as any;
    expect(cmd.handlerPath).toBe('./status-handler');
    expect(cmd._loadedHandler).toBeUndefined();
  });

  it('should support MCP interface', () => {
    const mcpTool = agentStatusCommand.toMCPTool();
    expect(mcpTool.name).toBe('agent_status');
    expect(mcpTool.description).toContain('agent');
  });

  it('should generate CLI command correctly', () => {
    const cli = agentStatusCommand.getCLIMetadata();
    expect(cli.path).toEqual(['agent', 'status']);
  });
});
```

### Coverage

- ✅ Framework features (P0-1 to P0-4)
- ✅ Parameter validation
- ✅ MCP interface generation
- ✅ CLI metadata
- ✅ Tree integration
- ❌ Business logic (relies on legacy implementations)
- ❌ Requirement acceptance criteria

## Autogenerated Tests (From Requirements)

### Purpose

Validate that implementation meets requirement acceptance criteria.

### Location

- `tests/requirements/req-{ID}/req-{ID}.{type}.test.js`

### Generation Command

```bash
sc requirement generate-tests REQ-WORKFLOW-259 --feature=agent-workflow --no-register
```

### Files Generated

1. `req-workflow-259.feature` - Gherkin scenarios (currently empty)
2. `req-workflow-259.steps.js` - Step definitions (stub)
3. `req-workflow-259.unit.test.js` - Unit test stubs
4. `req-workflow-259.e2e.test.js` - E2E test stubs

### Test Structure (Stubs)

```javascript
describe('REQ-workflow-259 Unit Tests', () => {
  test('should implement core functionality', () => {
    expect(true).toBe(true); // Replace with actual test
  });

  test('should handle error cases', () => {
    expect(true).toBe(true); // Replace with actual test
  });
});
```

### Coverage

- ✅ Requirement traceability (REQ-XXX in filename)
- ✅ Gherkin scenario structure
- ❌ Actual test implementation (stubs only)
- ❌ Framework features
- ❌ Parameter validation

## Comparison Matrix

| Aspect             | Manual Tests                      | Autogenerated Tests             |
| ------------------ | --------------------------------- | ------------------------------- |
| **Purpose**        | Framework validation              | Requirement compliance          |
| **Location**       | `packages/universal-command/`     | `tests/requirements/`           |
| **Test Count**     | 49 tests (Phase 4)                | 2-4 stubs per requirement       |
| **Coverage**       | Framework features (P0-1 to P0-4) | Business logic (when filled in) |
| **Maintenance**    | Manual                            | Generated + manual fill-in      |
| **Traceability**   | None (framework-focused)          | REQ-XXX linkage                 |
| **Completeness**   | ✅ 100% (all tests implemented)   | ❌ 0% (stubs only)              |
| **File Conflicts** | No (different naming)             | No (different location)         |

## File Naming Patterns

### Manual Tests

```
packages/universal-command/src/commands/
├── agent/__tests__/agent-commands.test.ts
├── workflow/__tests__/wip-commands.test.ts
└── planning/__tests__/feature-commands.test.ts
```

### Autogenerated Tests

```
tests/requirements/
├── req-workflow-259/
│   ├── req-workflow-259.feature
│   ├── req-workflow-259.steps.js
│   ├── req-workflow-259.unit.test.js
│   └── req-workflow-259.e2e.test.js
├── req-workflow-273/
│   └── ...
└── req-xxx/
    └── ...
```

**No conflicts** - Different locations and naming conventions.

## Recommendations

### Keep Both Strategies

**Manual Tests (Framework Validation)**

- Location: `packages/universal-command/src/commands/**/__tests__/`
- Purpose: Validate LazyUniversalCommand framework
- When: Every migrated command
- Coverage: P0-1 to P0-4 features

**Autogenerated Tests (Requirement Compliance)**

- Location: `tests/requirements/req-{ID}/`
- Purpose: Validate business requirements
- When: Requirement has detailed acceptance criteria
- Coverage: Business logic, edge cases, integration

### Workflow

1. **Migrate command** (Phase 4 example: agent commands)
   - Create schema: `agent/status.ts`
   - Create handler: `agent/status-handler.ts`
   - Create manual tests: `agent/__tests__/agent-commands.test.ts`
   - Validate framework features work ✅

2. **Generate requirement tests** (if requirement exists)

   ```bash
   sc requirement generate-tests REQ-WORKFLOW-259 --feature=agent-workflow
   ```

   - Stubs generated in `tests/requirements/req-workflow-259/`
   - Fill in actual test logic based on acceptance criteria
   - Validate business requirements ✅

3. **Run both test suites**

   ```bash
   # Framework tests
   npm test packages/universal-command/

   # Requirement tests
   npm test tests/requirements/
   ```

## Current Status

### Phase 4 Manual Tests (Created)

- ✅ Agent commands: 19 tests (100% complete)
- ✅ WIP commands: 30 tests (100% complete)
- ⏳ Feature commands: 0 tests (pending - schemas created)

### Phase 4 Autogenerated Tests

- ✅ REQ-WORKFLOW-259 (agent): 4 files (stubs only)
- ✅ REQ-WORKFLOW-273 (wip): 4 files (stubs only)
- ✅ REQ-WORKFLOW-219 (planning): 4 files (existing implementation)

### Next Steps

1. **Create manual tests for feature commands**
   - `planning/__tests__/feature-commands.test.ts`
   - 3 commands × 6 tests = ~18 tests
   - Same pattern as agent/wip tests

2. **✅ Generate autogenerated tests for all Phase 4 requirements** (COMPLETE)

   ```bash
   # Generated 2026-01-17
   sc requirement generate-tests REQ-WORKFLOW-259 --feature=agent-workflow --no-register
   sc requirement generate-tests REQ-WORKFLOW-273 --feature=wip-registry --no-register
   # REQ-WORKFLOW-219 tests already exist
   ```

3. **Fill in autogenerated test stubs**
   - Based on acceptance criteria
   - Test actual business logic
   - Ensure requirement compliance

4. **Update MIGRATION-STATUS.md**
   - Document both test strategies
   - Track manual test count (framework)
   - Track autogenerated test count (requirements)

## Summary

**Both test strategies are complementary and serve different purposes:**

- **Manual tests** validate the universal-command framework works correctly
- **Autogenerated tests** validate requirements are met

**No conflicts** - Different locations, different purposes, both valuable.

**Recommendation**: Continue with both strategies for complete coverage.
